{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os import getcwd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateparser = lambda x: pd.datetime.strptime(x, \"%Y-%m-%d\")\n",
    "\n",
    "df = pd.read_csv(getcwd()+\"\\\\Stocks\\\\a.us.txt\", parse_dates=['Date'], date_parser=dateparser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>OpenInt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1999-11-18</td>\n",
       "      <td>30.713</td>\n",
       "      <td>33.754</td>\n",
       "      <td>27.002</td>\n",
       "      <td>29.702</td>\n",
       "      <td>66277506</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1999-11-19</td>\n",
       "      <td>28.986</td>\n",
       "      <td>29.027</td>\n",
       "      <td>26.872</td>\n",
       "      <td>27.257</td>\n",
       "      <td>16142920</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1999-11-22</td>\n",
       "      <td>27.886</td>\n",
       "      <td>29.702</td>\n",
       "      <td>27.044</td>\n",
       "      <td>29.702</td>\n",
       "      <td>6970266</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1999-11-23</td>\n",
       "      <td>28.688</td>\n",
       "      <td>29.446</td>\n",
       "      <td>27.002</td>\n",
       "      <td>27.002</td>\n",
       "      <td>6332082</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1999-11-24</td>\n",
       "      <td>27.083</td>\n",
       "      <td>28.309</td>\n",
       "      <td>27.002</td>\n",
       "      <td>27.717</td>\n",
       "      <td>5132147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date    Open    High     Low   Close    Volume  OpenInt\n",
       "0 1999-11-18  30.713  33.754  27.002  29.702  66277506        0\n",
       "1 1999-11-19  28.986  29.027  26.872  27.257  16142920        0\n",
       "2 1999-11-22  27.886  29.702  27.044  29.702   6970266        0\n",
       "3 1999-11-23  28.688  29.446  27.002  27.002   6332082        0\n",
       "4 1999-11-24  27.083  28.309  27.002  27.717   5132147        0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4521"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict next 4 High,Open,Low given last 20 High,Open,Low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['High', 'Open', 'Low']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Open</th>\n",
       "      <th>Low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>33.754</td>\n",
       "      <td>30.713</td>\n",
       "      <td>27.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>29.027</td>\n",
       "      <td>28.986</td>\n",
       "      <td>26.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>29.702</td>\n",
       "      <td>27.886</td>\n",
       "      <td>27.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>29.446</td>\n",
       "      <td>28.688</td>\n",
       "      <td>27.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>28.309</td>\n",
       "      <td>27.083</td>\n",
       "      <td>27.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     High    Open     Low\n",
       "0  33.754  30.713  27.002\n",
       "1  29.027  28.986  26.872\n",
       "2  29.702  27.886  27.044\n",
       "3  29.446  28.688  27.002\n",
       "4  28.309  27.083  27.002"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change time series data into data subsets for encoder decoder supervised learning\n",
    "# looking back n_past data points to predict n_future data points\n",
    "def create_datasets(series, n_past, n_future):\n",
    "    data = [] # encoder input\n",
    "    target = [] # target sequence\n",
    "    data2 = [] # decoder input\n",
    "    \n",
    "    for i in range(len(series) - (n_past+n_future-1)):\n",
    "        \n",
    "        indicies = range(i,n_past+i)\n",
    "        target_indicies = range(n_past+i, n_past+i+n_future)\n",
    "        indicies2 = range(n_past+i, n_past+i+n_future-1)\n",
    "        \n",
    "        data.append(series[indicies])\n",
    "        \n",
    "        target.append(series[target_indicies])\n",
    "\n",
    "        tmp = series[indicies2]\n",
    "        filler = np.zeros((1, 3)) # using 0 as start of sequence\n",
    "        tmp = np.concatenate((filler, tmp), axis=0) # tmp => target(t-1)\n",
    "        \n",
    "        data2.append(tmp)\n",
    "    \n",
    "    return np.array(data), np.array(target), np.array(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_past = 20\n",
    "n_future = 4\n",
    "n_feat = 3\n",
    "\n",
    "data, target, data2 = create_datasets(data.values, n_past, n_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4498, 20, 3), (4498, 4, 3), (4498, 4, 3))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, target.shape, data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33.754, 30.713, 27.002],\n",
       "       [29.027, 28.986, 26.872],\n",
       "       [29.702, 27.886, 27.044],\n",
       "       [29.446, 28.688, 27.002],\n",
       "       [28.309, 27.083, 27.002],\n",
       "       [28.012, 27.594, 27.509],\n",
       "       [28.65 , 27.676, 27.38 ],\n",
       "       [28.986, 28.35 , 27.634],\n",
       "       [29.324, 28.48 , 28.273],\n",
       "       [30.375, 29.532, 29.155],\n",
       "       [30.842, 30.336, 29.909],\n",
       "       [31.348, 30.547, 30.505],\n",
       "       [31.052, 30.883, 29.909],\n",
       "       [30.795, 30.547, 30.249],\n",
       "       [31.012, 30.547, 30.547],\n",
       "       [31.012, 30.842, 30.209],\n",
       "       [31.221, 30.713, 29.958],\n",
       "       [30.635, 30.635, 28.391],\n",
       "       [28.561, 28.35 , 27.676],\n",
       "       [31.896, 28.35 , 28.35 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31.808, 31.308, 30.674],\n",
       "       [31.687, 31.221, 31.134],\n",
       "       [31.517, 31.517, 31.052],\n",
       "       [32.104, 31.47 , 31.261]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.   ,  0.   ,  0.   ],\n",
       "       [31.808, 31.308, 30.674],\n",
       "       [31.687, 31.221, 31.134],\n",
       "       [31.517, 31.517, 31.052]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reshape((data.shape[0], data.shape[1]*data.shape[2]))\n",
    "target = target.reshape((target.shape[0], target.shape[1]*target.shape[2]))\n",
    "data2 = data2.reshape((data2.shape[0], data2.shape[1]*data2.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4498, 60), (4498, 12), (4498, 12))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, target.shape, data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize along axis=0\n",
    "def randomize_data(data, target, data2, num_feat, n_future_steps):\n",
    "    \n",
    "    tmp = np.concatenate((data, target, data2), axis=1)\n",
    "    \n",
    "    np.random.seed(101)\n",
    "    np.random.shuffle(tmp)\n",
    "    \n",
    "    tmp_data = tmp[:, :-(2*num_feat*n_future_steps)]\n",
    "    tmp_target = tmp[:, -(2*num_feat*n_future_steps):-(num_feat*n_future_steps)]\n",
    "    tmp_data2 = tmp[:, -(num_feat*n_future_steps):]\n",
    "    \n",
    "    return tmp_data, tmp_target, tmp_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4498, 60) (4498, 12) (4498, 12)\n"
     ]
    }
   ],
   "source": [
    "data, target, data2 = randomize_data(data, target, data2, n_feat, n_future)\n",
    "print(data.shape, target.shape, data2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SPLIT = int(data.shape[0] * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_data = MinMaxScaler()\n",
    "scaler_target = MinMaxScaler()\n",
    "scaler_data2 = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data[:TRAIN_SPLIT]\n",
    "x_val = data[TRAIN_SPLIT:]\n",
    "\n",
    "y_train = target[:TRAIN_SPLIT]\n",
    "y_val = target[TRAIN_SPLIT:]\n",
    "\n",
    "x2_train = data2[:TRAIN_SPLIT]\n",
    "x2_val = data2[TRAIN_SPLIT:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = scaler_data.fit_transform(x_train)\n",
    "x_val = scaler_data.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = scaler_target.fit_transform(y_train)\n",
    "y_val = scaler_target.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_train = scaler_data2.fit_transform(x2_train)\n",
    "x2_val = scaler_data2.transform(x2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.15725224, 0.16304451,\n",
       "       0.17722913, 0.15547522, 0.15753651, 0.17029845, 0.15533778,\n",
       "       0.16036294, 0.1711604 ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3598, 60) (900, 60)\n",
      "(3598, 12) (900, 12)\n",
      "(3598, 12) (900, 12)\n",
      "(3598, 20, 3) (900, 20, 3)\n",
      "(3598, 4, 3) (900, 4, 3)\n",
      "(3598, 4, 3) (900, 4, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_val.shape)\n",
    "print(y_train.shape, y_val.shape)\n",
    "print(x2_train.shape, x2_val.shape)\n",
    "\n",
    "x_train = x_train.reshape((TRAIN_SPLIT, n_past, n_feat))\n",
    "x_val = x_val.reshape((len(data) - TRAIN_SPLIT, n_past, n_feat))\n",
    "\n",
    "y_train = y_train.reshape((TRAIN_SPLIT, n_future, n_feat))\n",
    "y_val = y_val.reshape((len(data) - TRAIN_SPLIT, n_future, n_feat))\n",
    "\n",
    "x2_train = x2_train.reshape((TRAIN_SPLIT, n_future, n_feat))\n",
    "x2_val = x2_val.reshape((len(data) - TRAIN_SPLIT, n_future, n_feat))\n",
    "\n",
    "print(x_train.shape, x_val.shape)\n",
    "print(y_train.shape, y_val.shape)\n",
    "print(x2_train.shape, x2_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16490506, 0.17122177, 0.18008177],\n",
       "       [0.16401669, 0.17111629, 0.18957596],\n",
       "       [0.16315272, 0.16973314, 0.18326483],\n",
       "       [0.16289746, 0.16647039, 0.18703642],\n",
       "       [0.17283752, 0.1693151 , 0.18319874],\n",
       "       [0.17415845, 0.17896059, 0.1894437 ],\n",
       "       [0.17623083, 0.18531766, 0.18985549],\n",
       "       [0.16816638, 0.17448451, 0.18705366],\n",
       "       [0.16666748, 0.17457954, 0.1809208 ],\n",
       "       [0.1664986 , 0.17206804, 0.18357322],\n",
       "       [0.15898011, 0.17189707, 0.17452172],\n",
       "       [0.1457949 , 0.14492264, 0.15243966],\n",
       "       [0.14865187, 0.14298204, 0.16049032],\n",
       "       [0.15169538, 0.15672294, 0.16935409],\n",
       "       [0.15188192, 0.16069941, 0.16728345],\n",
       "       [0.14963617, 0.15466333, 0.16569743],\n",
       "       [0.15663793, 0.16092441, 0.168495  ],\n",
       "       [0.15757623, 0.15994582, 0.1684179 ],\n",
       "       [0.15244153, 0.15748764, 0.17628339],\n",
       "       [0.15568026, 0.16036294, 0.1797152 ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        ],\n",
       "       [0.15725224, 0.16304451, 0.17722913],\n",
       "       [0.15547522, 0.15753651, 0.17029845],\n",
       "       [0.15533778, 0.16036294, 0.1711604 ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15725224, 0.16304451, 0.17722913],\n",
       "       [0.15547522, 0.15753651, 0.17029845],\n",
       "       [0.15533778, 0.16036294, 0.1711604 ],\n",
       "       [0.14825916, 0.15608059, 0.16133587]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0159 - val_loss: 9.3491e-04\n",
      "Epoch 2/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 6.4685e-04 - val_loss: 4.3345e-04\n",
      "Epoch 3/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.5348e-04 - val_loss: 3.4760e-04\n",
      "Epoch 4/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.0769e-04 - val_loss: 3.1621e-04\n",
      "Epoch 5/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 3.8183e-04 - val_loss: 2.8709e-04\n",
      "Epoch 6/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5907e-04 - val_loss: 2.6610e-04\n",
      "Epoch 7/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4288e-04 - val_loss: 2.5124e-04\n",
      "Epoch 8/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.2506e-04 - val_loss: 2.3467e-04\n",
      "Epoch 9/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.1551e-04 - val_loss: 2.2216e-04\n",
      "Epoch 10/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.0071e-04 - val_loss: 2.1061e-04\n",
      "Epoch 11/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 2.8759e-04 - val_loss: 2.0099e-04\n",
      "Epoch 12/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 2.7719e-04 - val_loss: 2.0257e-04\n",
      "Epoch 13/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 2.6834e-04 - val_loss: 1.8300e-04\n",
      "Epoch 14/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 2.6006e-04 - val_loss: 1.7408e-04\n",
      "Epoch 15/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 2.5102e-04 - val_loss: 1.6691e-04\n",
      "Epoch 16/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 2.4473e-04 - val_loss: 1.5989e-04\n",
      "Epoch 17/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 2.3627e-04 - val_loss: 1.6703e-04\n",
      "Epoch 18/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 2.2650e-04 - val_loss: 1.4823e-04\n",
      "Epoch 19/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 2.2209e-04 - val_loss: 1.4033e-04\n",
      "Epoch 20/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 2.1083e-04 - val_loss: 1.3506e-04\n",
      "Epoch 21/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 2.0095e-04 - val_loss: 1.3359e-04\n",
      "Epoch 22/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.9888e-04 - val_loss: 1.2745e-04\n",
      "Epoch 23/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.9084e-04 - val_loss: 1.1988e-04\n",
      "Epoch 24/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.8259e-04 - val_loss: 1.2010e-04\n",
      "Epoch 25/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.7843e-04 - val_loss: 1.1434e-04\n",
      "Epoch 26/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.7408e-04 - val_loss: 1.1231e-04\n",
      "Epoch 27/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.6854e-04 - val_loss: 1.0983e-04\n",
      "Epoch 28/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.6498e-04 - val_loss: 1.0923e-04\n",
      "Epoch 29/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.6449e-04 - val_loss: 1.0759e-04\n",
      "Epoch 30/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.6031e-04 - val_loss: 1.0883e-04\n",
      "Epoch 31/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.5688e-04 - val_loss: 1.0881e-04\n",
      "Epoch 32/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.5547e-04 - val_loss: 1.0573e-04\n",
      "Epoch 33/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.5310e-04 - val_loss: 1.0406e-04\n",
      "Epoch 34/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.4960e-04 - val_loss: 1.1223e-04\n",
      "Epoch 35/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.5204e-04 - val_loss: 1.0256e-04\n",
      "Epoch 36/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.4658e-04 - val_loss: 1.0156e-04\n",
      "Epoch 37/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.4419e-04 - val_loss: 1.0684e-04\n",
      "Epoch 38/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.4308e-04 - val_loss: 1.0188e-04\n",
      "Epoch 39/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.4137e-04 - val_loss: 1.0013e-04\n",
      "Epoch 40/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.3964e-04 - val_loss: 1.2099e-04\n",
      "Epoch 41/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.3728e-04 - val_loss: 1.0047e-04\n",
      "Epoch 42/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.3771e-04 - val_loss: 9.9127e-05\n",
      "Epoch 43/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.3370e-04 - val_loss: 9.9624e-05\n",
      "Epoch 44/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.3161e-04 - val_loss: 1.0052e-04\n",
      "Epoch 45/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.3006e-04 - val_loss: 9.7171e-05\n",
      "Epoch 46/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.2998e-04 - val_loss: 9.6776e-05\n",
      "Epoch 47/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.2780e-04 - val_loss: 9.8030e-05\n",
      "Epoch 48/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.2865e-04 - val_loss: 9.9256e-05\n",
      "Epoch 49/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.2569e-04 - val_loss: 9.3798e-05\n",
      "Epoch 50/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.2468e-04 - val_loss: 9.2850e-05\n",
      "Epoch 51/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.2335e-04 - val_loss: 1.0006e-04\n",
      "Epoch 52/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.2162e-04 - val_loss: 9.2011e-05\n",
      "Epoch 53/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.1978e-04 - val_loss: 9.1024e-05\n",
      "Epoch 54/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.2006e-04 - val_loss: 9.2253e-05\n",
      "Epoch 55/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.1901e-04 - val_loss: 9.0098e-05\n",
      "Epoch 56/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.1626e-04 - val_loss: 8.9753e-05\n",
      "Epoch 57/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.1746e-04 - val_loss: 8.8021e-05\n",
      "Epoch 58/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.1512e-04 - val_loss: 8.8322e-05\n",
      "Epoch 59/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.1290e-04 - val_loss: 8.8013e-05\n",
      "Epoch 60/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.1180e-04 - val_loss: 8.6709e-05\n",
      "Epoch 61/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.1089e-04 - val_loss: 8.5507e-05\n",
      "Epoch 62/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.0992e-04 - val_loss: 8.4918e-05\n",
      "Epoch 63/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.0867e-04 - val_loss: 8.4030e-05\n",
      "Epoch 64/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.0859e-04 - val_loss: 9.1738e-05\n",
      "Epoch 65/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.0790e-04 - val_loss: 8.5224e-05\n",
      "Epoch 66/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.0660e-04 - val_loss: 8.4058e-05\n",
      "Epoch 67/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.0525e-04 - val_loss: 8.5533e-05\n",
      "Epoch 68/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.0507e-04 - val_loss: 8.2125e-05\n",
      "Epoch 69/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.0401e-04 - val_loss: 8.0031e-05\n",
      "Epoch 70/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.0336e-04 - val_loss: 8.2015e-05\n",
      "Epoch 71/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.0159e-04 - val_loss: 8.0666e-05\n",
      "Epoch 72/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.0133e-04 - val_loss: 8.2940e-05\n",
      "Epoch 73/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 1.0009e-04 - val_loss: 7.8650e-05\n",
      "Epoch 74/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 9.9196e-05 - val_loss: 7.8261e-05\n",
      "Epoch 75/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 1s 7ms/step - loss: 9.8541e-05 - val_loss: 7.6467e-05\n",
      "Epoch 76/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 9.7867e-05 - val_loss: 7.5836e-05\n",
      "Epoch 77/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 9.7784e-05 - val_loss: 7.6096e-05\n",
      "Epoch 78/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 9.5946e-05 - val_loss: 7.4939e-05\n",
      "Epoch 79/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 9.6083e-05 - val_loss: 7.7298e-05\n",
      "Epoch 80/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 9.4848e-05 - val_loss: 7.4255e-05\n",
      "Epoch 81/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 9.4530e-05 - val_loss: 7.1784e-05\n",
      "Epoch 82/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 9.3557e-05 - val_loss: 7.5044e-05\n",
      "Epoch 83/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 9.3057e-05 - val_loss: 7.3888e-05\n",
      "Epoch 84/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 9.1593e-05 - val_loss: 7.1186e-05\n",
      "Epoch 85/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 9.2059e-05 - val_loss: 7.3964e-05\n",
      "Epoch 86/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 9.2191e-05 - val_loss: 7.0040e-05\n",
      "Epoch 87/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 9.0655e-05 - val_loss: 6.8588e-05\n",
      "Epoch 88/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 9.0292e-05 - val_loss: 7.3521e-05\n",
      "Epoch 89/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 8.9042e-05 - val_loss: 6.8369e-05\n",
      "Epoch 90/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 8.8273e-05 - val_loss: 6.9688e-05\n",
      "Epoch 91/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 8.6787e-05 - val_loss: 6.5822e-05\n",
      "Epoch 92/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 8.5898e-05 - val_loss: 6.6405e-05\n",
      "Epoch 93/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 8.6681e-05 - val_loss: 6.4137e-05\n",
      "Epoch 94/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 8.4540e-05 - val_loss: 6.4284e-05\n",
      "Epoch 95/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 8.4322e-05 - val_loss: 6.3129e-05\n",
      "Epoch 96/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 8.2811e-05 - val_loss: 6.2471e-05\n",
      "Epoch 97/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 8.3302e-05 - val_loss: 6.2349e-05\n",
      "Epoch 98/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 8.2043e-05 - val_loss: 6.3827e-05\n",
      "Epoch 99/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 8.2818e-05 - val_loss: 6.0673e-05\n",
      "Epoch 100/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 8.2385e-05 - val_loss: 5.9810e-05\n",
      "Epoch 101/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 8.0274e-05 - val_loss: 6.0973e-05\n",
      "Epoch 102/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 7.9905e-05 - val_loss: 6.1062e-05\n",
      "Epoch 103/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 7.9766e-05 - val_loss: 5.8124e-05\n",
      "Epoch 104/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 7.8581e-05 - val_loss: 5.8324e-05\n",
      "Epoch 105/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 7.7397e-05 - val_loss: 5.7804e-05\n",
      "Epoch 106/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 7.6847e-05 - val_loss: 5.9031e-05\n",
      "Epoch 107/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 7.6327e-05 - val_loss: 5.6854e-05\n",
      "Epoch 108/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 7.5816e-05 - val_loss: 5.7352e-05\n",
      "Epoch 109/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 7.5468e-05 - val_loss: 5.7491e-05\n",
      "Epoch 110/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 7.6885e-05 - val_loss: 5.4652e-05\n",
      "Epoch 111/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 7.6055e-05 - val_loss: 5.4015e-05\n",
      "Epoch 112/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 7.3860e-05 - val_loss: 5.5049e-05\n",
      "Epoch 113/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 7.3198e-05 - val_loss: 5.2377e-05\n",
      "Epoch 114/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 7.2738e-05 - val_loss: 5.3433e-05\n",
      "Epoch 115/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 7.1259e-05 - val_loss: 5.4346e-05\n",
      "Epoch 116/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 7.3285e-05 - val_loss: 5.3630e-05\n",
      "Epoch 117/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 7.0370e-05 - val_loss: 5.4553e-05\n",
      "Epoch 118/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 7.0857e-05 - val_loss: 5.1528e-05\n",
      "Epoch 119/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 7.0637e-05 - val_loss: 4.9663e-05\n",
      "Epoch 120/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 6.8833e-05 - val_loss: 5.4029e-05\n",
      "Epoch 121/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 6.8243e-05 - val_loss: 4.9735e-05\n",
      "Epoch 122/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 6.7350e-05 - val_loss: 4.9274e-05\n",
      "Epoch 123/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 6.7392e-05 - val_loss: 5.0956e-05\n",
      "Epoch 124/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 6.6489e-05 - val_loss: 4.8734e-05\n",
      "Epoch 125/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 6.6448e-05 - val_loss: 4.8040e-05\n",
      "Epoch 126/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 6.5691e-05 - val_loss: 5.2496e-05\n",
      "Epoch 127/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 6.5334e-05 - val_loss: 4.6433e-05\n",
      "Epoch 128/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 6.4493e-05 - val_loss: 4.6021e-05\n",
      "Epoch 129/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 6.4076e-05 - val_loss: 4.8276e-05\n",
      "Epoch 130/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 6.3973e-05 - val_loss: 4.5387e-05\n",
      "Epoch 131/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 6.3270e-05 - val_loss: 4.5430e-05\n",
      "Epoch 132/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 6.3571e-05 - val_loss: 4.6174e-05\n",
      "Epoch 133/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 6.2521e-05 - val_loss: 4.5372e-05\n",
      "Epoch 134/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 6.2323e-05 - val_loss: 4.3586e-05\n",
      "Epoch 135/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 6.1731e-05 - val_loss: 4.4982e-05\n",
      "Epoch 136/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 6.0780e-05 - val_loss: 5.0930e-05\n",
      "Epoch 137/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 6.0434e-05 - val_loss: 4.5316e-05\n",
      "Epoch 138/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 6.0754e-05 - val_loss: 4.3795e-05\n",
      "Epoch 139/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.9756e-05 - val_loss: 4.5807e-05\n",
      "Epoch 140/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.9077e-05 - val_loss: 4.2481e-05\n",
      "Epoch 141/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.8289e-05 - val_loss: 4.5510e-05\n",
      "Epoch 142/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.8387e-05 - val_loss: 4.3996e-05\n",
      "Epoch 143/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.7431e-05 - val_loss: 4.2389e-05\n",
      "Epoch 144/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.7849e-05 - val_loss: 4.4558e-05\n",
      "Epoch 145/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.6995e-05 - val_loss: 4.1522e-05\n",
      "Epoch 146/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.6185e-05 - val_loss: 4.2035e-05\n",
      "Epoch 147/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.6222e-05 - val_loss: 4.0600e-05\n",
      "Epoch 148/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.7050e-05 - val_loss: 4.0977e-05\n",
      "Epoch 149/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 1s 7ms/step - loss: 5.6101e-05 - val_loss: 4.0364e-05\n",
      "Epoch 150/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.5998e-05 - val_loss: 4.0558e-05\n",
      "Epoch 151/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.4859e-05 - val_loss: 4.1416e-05\n",
      "Epoch 152/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.4689e-05 - val_loss: 3.9456e-05\n",
      "Epoch 153/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.4880e-05 - val_loss: 4.3081e-05\n",
      "Epoch 154/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.4224e-05 - val_loss: 3.9007e-05\n",
      "Epoch 155/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.3553e-05 - val_loss: 4.0269e-05\n",
      "Epoch 156/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.3751e-05 - val_loss: 3.9624e-05\n",
      "Epoch 157/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.3091e-05 - val_loss: 4.1057e-05\n",
      "Epoch 158/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.3995e-05 - val_loss: 4.0600e-05\n",
      "Epoch 159/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.2895e-05 - val_loss: 3.8372e-05\n",
      "Epoch 160/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.2334e-05 - val_loss: 3.8030e-05\n",
      "Epoch 161/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.2756e-05 - val_loss: 4.0409e-05\n",
      "Epoch 162/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.1405e-05 - val_loss: 5.0424e-05\n",
      "Epoch 163/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.2096e-05 - val_loss: 3.9593e-05\n",
      "Epoch 164/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.1263e-05 - val_loss: 4.8999e-05\n",
      "Epoch 165/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.2037e-05 - val_loss: 3.7203e-05\n",
      "Epoch 166/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.1330e-05 - val_loss: 4.0274e-05\n",
      "Epoch 167/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.1201e-05 - val_loss: 3.6901e-05\n",
      "Epoch 168/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.0955e-05 - val_loss: 3.8136e-05\n",
      "Epoch 169/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.1674e-05 - val_loss: 3.8471e-05\n",
      "Epoch 170/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.1426e-05 - val_loss: 3.6682e-05\n",
      "Epoch 171/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.0112e-05 - val_loss: 3.6606e-05\n",
      "Epoch 172/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.0249e-05 - val_loss: 4.4284e-05\n",
      "Epoch 173/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.0888e-05 - val_loss: 3.8587e-05\n",
      "Epoch 174/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.0072e-05 - val_loss: 4.3227e-05\n",
      "Epoch 175/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 5.0950e-05 - val_loss: 3.9780e-05\n",
      "Epoch 176/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.9289e-05 - val_loss: 3.6385e-05\n",
      "Epoch 177/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.9114e-05 - val_loss: 3.6064e-05\n",
      "Epoch 178/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.9439e-05 - val_loss: 3.5654e-05\n",
      "Epoch 179/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.9700e-05 - val_loss: 3.6005e-05\n",
      "Epoch 180/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.9048e-05 - val_loss: 3.6286e-05\n",
      "Epoch 181/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.8803e-05 - val_loss: 3.6056e-05\n",
      "Epoch 182/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.8889e-05 - val_loss: 3.5902e-05\n",
      "Epoch 183/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.9327e-05 - val_loss: 3.6090e-05\n",
      "Epoch 184/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.9153e-05 - val_loss: 3.8854e-05\n",
      "Epoch 185/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.8643e-05 - val_loss: 4.4095e-05\n",
      "Epoch 186/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.9176e-05 - val_loss: 3.5946e-05\n",
      "Epoch 187/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.8866e-05 - val_loss: 3.5658e-05\n",
      "Epoch 188/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.8435e-05 - val_loss: 3.7066e-05\n",
      "Epoch 189/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.9202e-05 - val_loss: 3.5876e-05\n",
      "Epoch 190/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.8526e-05 - val_loss: 3.5315e-05\n",
      "Epoch 191/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.7625e-05 - val_loss: 3.7847e-05\n",
      "Epoch 192/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.7884e-05 - val_loss: 3.5360e-05\n",
      "Epoch 193/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.7910e-05 - val_loss: 3.7982e-05\n",
      "Epoch 194/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.8067e-05 - val_loss: 3.9072e-05\n",
      "Epoch 195/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.8539e-05 - val_loss: 3.8652e-05\n",
      "Epoch 196/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.7957e-05 - val_loss: 3.5430e-05\n",
      "Epoch 197/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.7046e-05 - val_loss: 3.7928e-05\n",
      "Epoch 198/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.7463e-05 - val_loss: 3.8691e-05\n",
      "Epoch 199/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.8033e-05 - val_loss: 3.8120e-05\n",
      "Epoch 200/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.7575e-05 - val_loss: 3.8929e-05\n",
      "Epoch 201/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.7119e-05 - val_loss: 3.7756e-05\n",
      "Epoch 202/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.7183e-05 - val_loss: 3.7895e-05\n",
      "Epoch 203/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.7086e-05 - val_loss: 3.4793e-05\n",
      "Epoch 204/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.6731e-05 - val_loss: 3.6244e-05\n",
      "Epoch 205/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.6847e-05 - val_loss: 3.5332e-05\n",
      "Epoch 206/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.6854e-05 - val_loss: 3.6735e-05\n",
      "Epoch 207/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.6568e-05 - val_loss: 3.4416e-05\n",
      "Epoch 208/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.6704e-05 - val_loss: 3.7227e-05\n",
      "Epoch 209/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.6431e-05 - val_loss: 3.6265e-05\n",
      "Epoch 210/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.6506e-05 - val_loss: 3.6980e-05\n",
      "Epoch 211/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.6814e-05 - val_loss: 3.4543e-05\n",
      "Epoch 212/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.6333e-05 - val_loss: 3.5603e-05\n",
      "Epoch 213/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.6116e-05 - val_loss: 3.5721e-05\n",
      "Epoch 214/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.6544e-05 - val_loss: 3.4596e-05\n",
      "Epoch 215/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.5631e-05 - val_loss: 3.7660e-05\n",
      "Epoch 216/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.6372e-05 - val_loss: 3.6941e-05\n",
      "Epoch 217/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.5769e-05 - val_loss: 3.5663e-05\n",
      "Epoch 218/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.5613e-05 - val_loss: 3.4909e-05\n",
      "Epoch 219/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.6378e-05 - val_loss: 3.6160e-05\n",
      "Epoch 220/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.5702e-05 - val_loss: 3.5315e-05\n",
      "Epoch 221/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.5593e-05 - val_loss: 3.6675e-05\n",
      "Epoch 222/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.5370e-05 - val_loss: 3.4626e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.5341e-05 - val_loss: 3.4013e-05\n",
      "Epoch 224/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.4924e-05 - val_loss: 3.4607e-05\n",
      "Epoch 225/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.5304e-05 - val_loss: 3.4499e-05\n",
      "Epoch 226/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.5568e-05 - val_loss: 3.8396e-05\n",
      "Epoch 227/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.5122e-05 - val_loss: 3.4458e-05\n",
      "Epoch 228/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.4955e-05 - val_loss: 3.3598e-05\n",
      "Epoch 229/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.4506e-05 - val_loss: 3.4325e-05\n",
      "Epoch 230/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.5189e-05 - val_loss: 3.4589e-05\n",
      "Epoch 231/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.5299e-05 - val_loss: 3.3872e-05\n",
      "Epoch 232/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.5105e-05 - val_loss: 3.3914e-05\n",
      "Epoch 233/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.5909e-05 - val_loss: 3.4976e-05\n",
      "Epoch 234/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.5079e-05 - val_loss: 3.5101e-05\n",
      "Epoch 235/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.4871e-05 - val_loss: 3.5626e-05\n",
      "Epoch 236/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.4412e-05 - val_loss: 3.4017e-05\n",
      "Epoch 237/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.4581e-05 - val_loss: 3.3756e-05\n",
      "Epoch 238/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.4354e-05 - val_loss: 3.3527e-05\n",
      "Epoch 239/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.4534e-05 - val_loss: 3.4327e-05\n",
      "Epoch 240/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.4937e-05 - val_loss: 3.3492e-05\n",
      "Epoch 241/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.4121e-05 - val_loss: 3.6216e-05\n",
      "Epoch 242/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.4131e-05 - val_loss: 3.3378e-05\n",
      "Epoch 243/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.4086e-05 - val_loss: 3.4012e-05\n",
      "Epoch 244/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.4281e-05 - val_loss: 3.4942e-05\n",
      "Epoch 245/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.3666e-05 - val_loss: 3.2909e-05\n",
      "Epoch 246/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.4353e-05 - val_loss: 3.4930e-05\n",
      "Epoch 247/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.4414e-05 - val_loss: 4.2996e-05\n",
      "Epoch 248/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.4088e-05 - val_loss: 3.5932e-05\n",
      "Epoch 249/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.4203e-05 - val_loss: 3.3076e-05\n",
      "Epoch 250/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.3908e-05 - val_loss: 3.3359e-05\n",
      "Epoch 251/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.3299e-05 - val_loss: 3.3174e-05\n",
      "Epoch 252/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.3214e-05 - val_loss: 3.7035e-05\n",
      "Epoch 253/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.4180e-05 - val_loss: 3.2793e-05\n",
      "Epoch 254/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.3172e-05 - val_loss: 3.5533e-05\n",
      "Epoch 255/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.3688e-05 - val_loss: 3.6992e-05\n",
      "Epoch 256/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.3449e-05 - val_loss: 3.7613e-05\n",
      "Epoch 257/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.3126e-05 - val_loss: 3.3833e-05\n",
      "Epoch 258/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.3157e-05 - val_loss: 3.2754e-05\n",
      "Epoch 259/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.2841e-05 - val_loss: 3.4418e-05\n",
      "Epoch 260/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.3448e-05 - val_loss: 3.2833e-05\n",
      "Epoch 261/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.3035e-05 - val_loss: 3.4122e-05\n",
      "Epoch 262/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.3522e-05 - val_loss: 3.4812e-05\n",
      "Epoch 263/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.2894e-05 - val_loss: 3.4549e-05\n",
      "Epoch 264/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.3732e-05 - val_loss: 3.2692e-05\n",
      "Epoch 265/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.2653e-05 - val_loss: 3.2932e-05\n",
      "Epoch 266/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.2569e-05 - val_loss: 3.2984e-05\n",
      "Epoch 267/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.2727e-05 - val_loss: 3.2528e-05\n",
      "Epoch 268/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.2053e-05 - val_loss: 3.4368e-05\n",
      "Epoch 269/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.2471e-05 - val_loss: 3.5793e-05\n",
      "Epoch 270/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.3160e-05 - val_loss: 3.6090e-05\n",
      "Epoch 271/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.1945e-05 - val_loss: 3.3270e-05\n",
      "Epoch 272/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.2647e-05 - val_loss: 3.5191e-05\n",
      "Epoch 273/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.2593e-05 - val_loss: 3.2467e-05\n",
      "Epoch 274/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.2576e-05 - val_loss: 3.4151e-05\n",
      "Epoch 275/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.3798e-05 - val_loss: 3.4170e-05\n",
      "Epoch 276/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.3366e-05 - val_loss: 3.3750e-05\n",
      "Epoch 277/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.2254e-05 - val_loss: 3.3735e-05\n",
      "Epoch 278/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.2084e-05 - val_loss: 3.2113e-05\n",
      "Epoch 279/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.1883e-05 - val_loss: 3.2826e-05\n",
      "Epoch 280/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.1717e-05 - val_loss: 3.4728e-05\n",
      "Epoch 281/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.1934e-05 - val_loss: 3.3549e-05\n",
      "Epoch 282/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.2271e-05 - val_loss: 3.2962e-05\n",
      "Epoch 283/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.2563e-05 - val_loss: 3.3649e-05\n",
      "Epoch 284/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.2190e-05 - val_loss: 3.4619e-05\n",
      "Epoch 285/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.1819e-05 - val_loss: 3.2076e-05\n",
      "Epoch 286/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.2084e-05 - val_loss: 3.4387e-05\n",
      "Epoch 287/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.1812e-05 - val_loss: 3.5307e-05\n",
      "Epoch 288/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.1347e-05 - val_loss: 3.4408e-05\n",
      "Epoch 289/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.1673e-05 - val_loss: 3.2409e-05\n",
      "Epoch 290/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.1778e-05 - val_loss: 3.1939e-05\n",
      "Epoch 291/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.1167e-05 - val_loss: 3.2624e-05\n",
      "Epoch 292/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.1393e-05 - val_loss: 3.3430e-05\n",
      "Epoch 293/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.1737e-05 - val_loss: 3.2471e-05\n",
      "Epoch 294/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.1587e-05 - val_loss: 3.1622e-05\n",
      "Epoch 295/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.1449e-05 - val_loss: 3.2062e-05\n",
      "Epoch 296/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.1347e-05 - val_loss: 3.3425e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.1412e-05 - val_loss: 3.2226e-05\n",
      "Epoch 298/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.1382e-05 - val_loss: 3.5546e-05\n",
      "Epoch 299/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.1021e-05 - val_loss: 3.2758e-05\n",
      "Epoch 300/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.1246e-05 - val_loss: 3.4880e-05\n",
      "Epoch 301/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.1000e-05 - val_loss: 3.4143e-05\n",
      "Epoch 302/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.0847e-05 - val_loss: 3.3125e-05\n",
      "Epoch 303/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.0736e-05 - val_loss: 3.1428e-05\n",
      "Epoch 304/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.0996e-05 - val_loss: 3.2156e-05\n",
      "Epoch 305/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.0313e-05 - val_loss: 3.2101e-05\n",
      "Epoch 306/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.0806e-05 - val_loss: 3.2498e-05\n",
      "Epoch 307/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.0382e-05 - val_loss: 3.3017e-05\n",
      "Epoch 308/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.1198e-05 - val_loss: 3.2310e-05\n",
      "Epoch 309/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.1093e-05 - val_loss: 3.4068e-05\n",
      "Epoch 310/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.0534e-05 - val_loss: 3.4796e-05\n",
      "Epoch 311/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.0528e-05 - val_loss: 3.1849e-05\n",
      "Epoch 312/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.0227e-05 - val_loss: 3.5810e-05\n",
      "Epoch 313/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.0819e-05 - val_loss: 3.3426e-05\n",
      "Epoch 314/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.0570e-05 - val_loss: 3.2633e-05\n",
      "Epoch 315/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.0327e-05 - val_loss: 3.1371e-05\n",
      "Epoch 316/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.0337e-05 - val_loss: 3.4095e-05\n",
      "Epoch 317/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.0787e-05 - val_loss: 3.4757e-05\n",
      "Epoch 318/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.0742e-05 - val_loss: 3.2003e-05\n",
      "Epoch 319/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.0106e-05 - val_loss: 3.2475e-05\n",
      "Epoch 320/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.0124e-05 - val_loss: 3.2158e-05\n",
      "Epoch 321/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.9978e-05 - val_loss: 3.1014e-05\n",
      "Epoch 322/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.0003e-05 - val_loss: 3.3133e-05\n",
      "Epoch 323/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.9677e-05 - val_loss: 3.1499e-05\n",
      "Epoch 324/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.9747e-05 - val_loss: 3.1304e-05\n",
      "Epoch 325/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.9789e-05 - val_loss: 3.3970e-05\n",
      "Epoch 326/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.0408e-05 - val_loss: 3.1438e-05\n",
      "Epoch 327/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.0627e-05 - val_loss: 3.1880e-05\n",
      "Epoch 328/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.9822e-05 - val_loss: 3.1898e-05\n",
      "Epoch 329/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.9343e-05 - val_loss: 3.0655e-05\n",
      "Epoch 330/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.9747e-05 - val_loss: 3.1109e-05\n",
      "Epoch 331/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.9797e-05 - val_loss: 3.2272e-05\n",
      "Epoch 332/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.0626e-05 - val_loss: 3.2365e-05\n",
      "Epoch 333/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.9518e-05 - val_loss: 3.2748e-05\n",
      "Epoch 334/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.9454e-05 - val_loss: 3.2189e-05\n",
      "Epoch 335/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.9382e-05 - val_loss: 3.2803e-05\n",
      "Epoch 336/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.9218e-05 - val_loss: 3.1025e-05\n",
      "Epoch 337/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.9380e-05 - val_loss: 3.2593e-05\n",
      "Epoch 338/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.9440e-05 - val_loss: 3.2292e-05\n",
      "Epoch 339/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.9081e-05 - val_loss: 3.4475e-05\n",
      "Epoch 340/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 4.0009e-05 - val_loss: 3.1742e-05\n",
      "Epoch 341/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.9393e-05 - val_loss: 3.1463e-05\n",
      "Epoch 342/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.9399e-05 - val_loss: 3.2974e-05\n",
      "Epoch 343/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.9097e-05 - val_loss: 3.0612e-05\n",
      "Epoch 344/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.9131e-05 - val_loss: 3.1325e-05\n",
      "Epoch 345/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.8745e-05 - val_loss: 3.1664e-05\n",
      "Epoch 346/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.9412e-05 - val_loss: 3.1724e-05\n",
      "Epoch 347/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.9194e-05 - val_loss: 3.1534e-05\n",
      "Epoch 348/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.9038e-05 - val_loss: 3.1978e-05\n",
      "Epoch 349/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.8725e-05 - val_loss: 3.2051e-05\n",
      "Epoch 350/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.8897e-05 - val_loss: 3.3056e-05\n",
      "Epoch 351/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.8763e-05 - val_loss: 3.0926e-05\n",
      "Epoch 352/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.8818e-05 - val_loss: 3.2374e-05\n",
      "Epoch 353/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.9535e-05 - val_loss: 3.2827e-05\n",
      "Epoch 354/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.8314e-05 - val_loss: 3.4223e-05\n",
      "Epoch 355/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.8833e-05 - val_loss: 3.1809e-05\n",
      "Epoch 356/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.8380e-05 - val_loss: 3.0755e-05\n",
      "Epoch 357/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.9072e-05 - val_loss: 3.3656e-05\n",
      "Epoch 358/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.8533e-05 - val_loss: 3.2628e-05\n",
      "Epoch 359/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.8307e-05 - val_loss: 3.0855e-05\n",
      "Epoch 360/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.8331e-05 - val_loss: 3.1923e-05\n",
      "Epoch 361/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.8124e-05 - val_loss: 3.0885e-05\n",
      "Epoch 362/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.8439e-05 - val_loss: 3.1098e-05\n",
      "Epoch 363/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.8339e-05 - val_loss: 3.1755e-05\n",
      "Epoch 364/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.8142e-05 - val_loss: 3.1159e-05\n",
      "Epoch 365/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.8346e-05 - val_loss: 3.2330e-05\n",
      "Epoch 366/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.8228e-05 - val_loss: 3.0038e-05\n",
      "Epoch 367/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.8207e-05 - val_loss: 3.0851e-05\n",
      "Epoch 368/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.7897e-05 - val_loss: 3.0291e-05\n",
      "Epoch 369/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.7621e-05 - val_loss: 3.2068e-05\n",
      "Epoch 370/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.7870e-05 - val_loss: 3.1605e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.7678e-05 - val_loss: 3.1102e-05\n",
      "Epoch 372/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.8274e-05 - val_loss: 3.0320e-05\n",
      "Epoch 373/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.7659e-05 - val_loss: 3.2358e-05\n",
      "Epoch 374/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.8325e-05 - val_loss: 3.1310e-05\n",
      "Epoch 375/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.7586e-05 - val_loss: 3.2397e-05\n",
      "Epoch 376/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.7562e-05 - val_loss: 3.0442e-05\n",
      "Epoch 377/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.8037e-05 - val_loss: 3.0502e-05\n",
      "Epoch 378/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.8201e-05 - val_loss: 3.2037e-05\n",
      "Epoch 379/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.7863e-05 - val_loss: 3.0502e-05\n",
      "Epoch 380/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.7607e-05 - val_loss: 3.1135e-05\n",
      "Epoch 381/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.7672e-05 - val_loss: 3.1502e-05\n",
      "Epoch 382/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 3.7395e-05 - val_loss: 3.4589e-05\n",
      "Epoch 383/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.7505e-05 - val_loss: 3.2458e-05\n",
      "Epoch 384/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.7641e-05 - val_loss: 3.0682e-05\n",
      "Epoch 385/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.7395e-05 - val_loss: 3.2901e-05\n",
      "Epoch 386/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.7257e-05 - val_loss: 3.0354e-05\n",
      "Epoch 387/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.7174e-05 - val_loss: 3.1446e-05\n",
      "Epoch 388/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.7209e-05 - val_loss: 3.0825e-05\n",
      "Epoch 389/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.7104e-05 - val_loss: 3.0874e-05\n",
      "Epoch 390/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.8075e-05 - val_loss: 3.0861e-05\n",
      "Epoch 391/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.7347e-05 - val_loss: 3.0912e-05\n",
      "Epoch 392/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.7575e-05 - val_loss: 3.1554e-05\n",
      "Epoch 393/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.7380e-05 - val_loss: 3.0476e-05\n",
      "Epoch 394/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.7259e-05 - val_loss: 3.2844e-05\n",
      "Epoch 395/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.7389e-05 - val_loss: 2.9631e-05\n",
      "Epoch 396/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.6799e-05 - val_loss: 3.1141e-05\n",
      "Epoch 397/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.7299e-05 - val_loss: 3.5083e-05\n",
      "Epoch 398/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.7426e-05 - val_loss: 3.1821e-05\n",
      "Epoch 399/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.6942e-05 - val_loss: 3.0263e-05\n",
      "Epoch 400/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.6477e-05 - val_loss: 3.0884e-05\n",
      "Epoch 401/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.7194e-05 - val_loss: 3.1603e-05\n",
      "Epoch 402/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.7186e-05 - val_loss: 3.3135e-05\n",
      "Epoch 403/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.7213e-05 - val_loss: 3.0508e-05\n",
      "Epoch 404/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.6824e-05 - val_loss: 3.0462e-05\n",
      "Epoch 405/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.6787e-05 - val_loss: 2.9800e-05\n",
      "Epoch 406/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.6305e-05 - val_loss: 3.0771e-05\n",
      "Epoch 407/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.7075e-05 - val_loss: 3.1105e-05\n",
      "Epoch 408/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.6614e-05 - val_loss: 3.2142e-05\n",
      "Epoch 409/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.6560e-05 - val_loss: 3.2445e-05\n",
      "Epoch 410/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.6282e-05 - val_loss: 2.9437e-05\n",
      "Epoch 411/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.6699e-05 - val_loss: 2.9922e-05\n",
      "Epoch 412/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.6294e-05 - val_loss: 2.9761e-05\n",
      "Epoch 413/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.6198e-05 - val_loss: 3.0187e-05\n",
      "Epoch 414/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.6997e-05 - val_loss: 3.0230e-05\n",
      "Epoch 415/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.6324e-05 - val_loss: 3.0163e-05\n",
      "Epoch 416/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.6262e-05 - val_loss: 3.0127e-05\n",
      "Epoch 417/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.6054e-05 - val_loss: 2.9846e-05\n",
      "Epoch 418/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.6185e-05 - val_loss: 2.9474e-05\n",
      "Epoch 419/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.6112e-05 - val_loss: 2.9646e-05\n",
      "Epoch 420/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.7401e-05 - val_loss: 3.0292e-05\n",
      "Epoch 421/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.6090e-05 - val_loss: 3.0276e-05\n",
      "Epoch 422/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.6448e-05 - val_loss: 3.1250e-05\n",
      "Epoch 423/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.6052e-05 - val_loss: 3.0373e-05\n",
      "Epoch 424/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.6654e-05 - val_loss: 2.9874e-05\n",
      "Epoch 425/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5830e-05 - val_loss: 3.0846e-05\n",
      "Epoch 426/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.6230e-05 - val_loss: 3.0147e-05\n",
      "Epoch 427/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5939e-05 - val_loss: 3.0168e-05\n",
      "Epoch 428/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.6051e-05 - val_loss: 3.1952e-05\n",
      "Epoch 429/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.6305e-05 - val_loss: 3.1253e-05\n",
      "Epoch 430/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.6556e-05 - val_loss: 2.9001e-05\n",
      "Epoch 431/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.6054e-05 - val_loss: 3.0958e-05\n",
      "Epoch 432/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5905e-05 - val_loss: 3.1010e-05\n",
      "Epoch 433/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.6165e-05 - val_loss: 3.0309e-05\n",
      "Epoch 434/500\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 3.6037e-05 - val_loss: 3.0131e-05\n",
      "Epoch 435/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5937e-05 - val_loss: 3.1775e-05\n",
      "Epoch 436/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5332e-05 - val_loss: 3.3887e-05\n",
      "Epoch 437/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5682e-05 - val_loss: 2.9104e-05\n",
      "Epoch 438/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5436e-05 - val_loss: 3.0024e-05\n",
      "Epoch 439/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5662e-05 - val_loss: 3.2023e-05\n",
      "Epoch 440/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5938e-05 - val_loss: 3.1245e-05\n",
      "Epoch 441/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5930e-05 - val_loss: 3.2000e-05\n",
      "Epoch 442/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5975e-05 - val_loss: 2.9356e-05\n",
      "Epoch 443/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5336e-05 - val_loss: 3.1692e-05\n",
      "Epoch 444/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5862e-05 - val_loss: 3.1297e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.6090e-05 - val_loss: 3.0806e-05\n",
      "Epoch 446/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5401e-05 - val_loss: 3.0125e-05\n",
      "Epoch 447/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5506e-05 - val_loss: 3.0710e-05\n",
      "Epoch 448/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5153e-05 - val_loss: 2.9857e-05\n",
      "Epoch 449/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5194e-05 - val_loss: 3.0114e-05\n",
      "Epoch 450/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5277e-05 - val_loss: 2.9345e-05\n",
      "Epoch 451/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5381e-05 - val_loss: 3.1117e-05\n",
      "Epoch 452/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5555e-05 - val_loss: 2.8922e-05\n",
      "Epoch 453/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5012e-05 - val_loss: 3.0185e-05\n",
      "Epoch 454/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5419e-05 - val_loss: 3.1062e-05\n",
      "Epoch 455/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5248e-05 - val_loss: 3.0529e-05\n",
      "Epoch 456/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5117e-05 - val_loss: 2.9405e-05\n",
      "Epoch 457/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4842e-05 - val_loss: 2.9384e-05\n",
      "Epoch 458/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5085e-05 - val_loss: 2.9762e-05\n",
      "Epoch 459/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5080e-05 - val_loss: 2.9470e-05\n",
      "Epoch 460/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5091e-05 - val_loss: 2.9689e-05\n",
      "Epoch 461/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4424e-05 - val_loss: 3.0309e-05\n",
      "Epoch 462/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5274e-05 - val_loss: 2.9184e-05\n",
      "Epoch 463/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5375e-05 - val_loss: 2.9753e-05\n",
      "Epoch 464/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4824e-05 - val_loss: 3.0658e-05\n",
      "Epoch 465/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5069e-05 - val_loss: 2.9209e-05\n",
      "Epoch 466/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4974e-05 - val_loss: 3.0620e-05\n",
      "Epoch 467/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4842e-05 - val_loss: 3.1459e-05\n",
      "Epoch 468/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5658e-05 - val_loss: 2.9795e-05\n",
      "Epoch 469/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4507e-05 - val_loss: 3.0003e-05\n",
      "Epoch 470/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4847e-05 - val_loss: 2.9100e-05\n",
      "Epoch 471/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4616e-05 - val_loss: 3.0551e-05\n",
      "Epoch 472/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5029e-05 - val_loss: 2.9006e-05\n",
      "Epoch 473/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4661e-05 - val_loss: 2.9990e-05\n",
      "Epoch 474/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5044e-05 - val_loss: 3.0701e-05\n",
      "Epoch 475/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4802e-05 - val_loss: 2.9414e-05\n",
      "Epoch 476/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4856e-05 - val_loss: 3.0489e-05\n",
      "Epoch 477/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4754e-05 - val_loss: 2.9233e-05\n",
      "Epoch 478/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4288e-05 - val_loss: 2.9216e-05\n",
      "Epoch 479/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4572e-05 - val_loss: 2.9119e-05\n",
      "Epoch 480/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4611e-05 - val_loss: 2.9238e-05\n",
      "Epoch 481/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4013e-05 - val_loss: 3.3028e-05\n",
      "Epoch 482/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4607e-05 - val_loss: 3.0674e-05\n",
      "Epoch 483/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4804e-05 - val_loss: 2.9297e-05\n",
      "Epoch 484/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4777e-05 - val_loss: 2.8617e-05\n",
      "Epoch 485/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4213e-05 - val_loss: 3.3149e-05\n",
      "Epoch 486/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4327e-05 - val_loss: 2.9345e-05\n",
      "Epoch 487/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.5087e-05 - val_loss: 2.9807e-05\n",
      "Epoch 488/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4681e-05 - val_loss: 2.9942e-05\n",
      "Epoch 489/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4197e-05 - val_loss: 3.5812e-05\n",
      "Epoch 490/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4215e-05 - val_loss: 3.0011e-05\n",
      "Epoch 491/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4785e-05 - val_loss: 2.9879e-05\n",
      "Epoch 492/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4083e-05 - val_loss: 2.9698e-05\n",
      "Epoch 493/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4333e-05 - val_loss: 2.9334e-05\n",
      "Epoch 494/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4644e-05 - val_loss: 2.9825e-05\n",
      "Epoch 495/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4649e-05 - val_loss: 3.0002e-05\n",
      "Epoch 496/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4405e-05 - val_loss: 3.0235e-05\n",
      "Epoch 497/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4179e-05 - val_loss: 3.0503e-05\n",
      "Epoch 498/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4045e-05 - val_loss: 2.9656e-05\n",
      "Epoch 499/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.3883e-05 - val_loss: 3.1535e-05\n",
      "Epoch 500/500\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 3.4106e-05 - val_loss: 2.9529e-05\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "\n",
    "rnn_units = 50\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "encoder_inputs = Input(shape=(None, n_feat))\n",
    "encoder = LSTM(rnn_units, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, n_feat))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the \n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(rnn_units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "#####decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_dense = Dense(n_feat)\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Run training\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001), loss='Huber')\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "history = model.fit([x_train, x2_train], y_train,\n",
    "          epochs=500,\n",
    "          validation_data=([x_val, x2_val], y_val),\n",
    "          verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2771a075d68>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(len(history.history['loss']))\n",
    "plt.plot(epochs, history.history['loss'])\n",
    "plt.plot(epochs, history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x277240f9ef0>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs[10:], history.history['loss'][10:])\n",
    "plt.plot(epochs[10:], history.history['val_loss'][10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(rnn_units,))\n",
    "decoder_state_input_c = Input(shape=(rnn_units,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sequence(infenc, infdec, source, n_steps, cardinality):\n",
    "    \n",
    "    # encode\n",
    "    state = infenc.predict(source)\n",
    "    \n",
    "    # start of sequence input\n",
    "    target_seq = np.array([0.0 for _ in range(cardinality)]).reshape(1, 1, cardinality)\n",
    "    \n",
    "    # collect predictions\n",
    "    output = list()\n",
    "    \n",
    "    for t in range(n_steps):\n",
    "        \n",
    "        # predict next char\n",
    "        yhat, h, c = infdec.predict([target_seq] + state)\n",
    "        \n",
    "        # store prediction\n",
    "        output.append(yhat[0,0,:])\n",
    "        \n",
    "        # update state\n",
    "        state = [h, c]\n",
    "        \n",
    "        # update target sequence\n",
    "        target_seq = yhat\n",
    "    return np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " array([[0.10138843, 0.1019394 , 0.1113872 ],\n",
       "        [0.09834561, 0.10731035, 0.11167368],\n",
       "        [0.09549845, 0.1016641 , 0.10779662],\n",
       "        [0.09800199, 0.10096057, 0.11313792],\n",
       "        [0.10102649, 0.10432528, 0.11383231],\n",
       "        [0.10642563, 0.10742489, 0.11645366],\n",
       "        [0.11024793, 0.11120735, 0.12090397],\n",
       "        [0.11359367, 0.11825313, 0.12824969],\n",
       "        [0.11299372, 0.11904605, 0.12612139],\n",
       "        [0.11478476, 0.11915038, 0.12750074],\n",
       "        [0.11661239, 0.12388386, 0.13767542],\n",
       "        [0.11724482, 0.12161507, 0.12943506],\n",
       "        [0.11663612, 0.12230959, 0.1324089 ],\n",
       "        [0.12094612, 0.12409548, 0.13472595],\n",
       "        [0.11815787, 0.12567587, 0.13301877],\n",
       "        [0.11808045, 0.12312685, 0.13121247],\n",
       "        [0.12049016, 0.12424823, 0.12697206],\n",
       "        [0.11074545, 0.1199487 , 0.12624514],\n",
       "        [0.11330789, 0.11692764, 0.13118929],\n",
       "        [0.11235008, 0.11769234, 0.13280224]]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_val[0].shape), x_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = x_train[0].reshape((1,20,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1571975 , 0.16273393, 0.17313956],\n",
       "       [0.15900677, 0.16268696, 0.1740604 ],\n",
       "       [0.16031966, 0.16491485, 0.17612901],\n",
       "       [0.16040659, 0.16560136, 0.17710032]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sequence(encoder_model, decoder_model, test_data, 4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15725224, 0.16304451, 0.17722913],\n",
       "       [0.15547522, 0.15753651, 0.17029845],\n",
       "       [0.15533778, 0.16036294, 0.1711604 ],\n",
       "       [0.14825916, 0.15608059, 0.16133587]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
